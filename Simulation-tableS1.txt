##In this file, we give the code of the proposed group testing method with alpha=beta=1, five covariates and varying group sizes.
##One can change alpha and beta values in line 4 to obtain other results in the Table S1. 

alpha =  beta = 1 ## sensitivity and specificity

library(gtools)
library(doParallel)
library(doRNG)
library(ICsurv)

time1= date()

mm = 500 ### number of replicates

n.bs = 100 ## resampling sample size

n.cores = 25 ## number of cores used in the parallel computation

##n.cores = detectCores()

ccl <- makeCluster(n.cores) ## make cluster

registerDoParallel(ccl)

max.loops = 1000 ## maximum number of iteration

theta0 = c(0.5, 0.5, -0.5, -0.5, -0.5) ## trues value of regression parameters

p <- length(theta0) ### dimension of regression vector

tau = 2 ## the observation time C is generated from U(0,tau)

xlab.t = c(1,1.2,1.5,1.7)  ## times of interest, at which we obtain the survival function estimates

p.knots = length(xlab.t) ## length of times of interest

theta.all = matrix(1,mm,p)
see.theta.all = matrix(1,mm,p)
cp.theta.all = matrix(1,mm,p)

Lambda.all = matrix(1,mm,p.knots)
see.Lambda.all = matrix(1,mm,p.knots)
cp.Lambda.all = matrix(1,mm,p.knots)

theta.naive = matrix(1,mm,p)
see.theta.naive = matrix(1,mm,p)
cp.theta.naive = matrix(1,mm,p)

R.rate = c()

loop=c()

###############################
seed.start = 100

iter = 1
for( iter in 1:mm){

set.seed(seed.start+iter)

n = 7000  ##### group number

gs = sample(c(1,2,3,4), n, replace = TRUE)  ##### group size 

N = sum(gs) ## number of individuals

K_n = floor(10*n^(1/3)) ## number of knots in the piecewise constant function

loops = 0

diff.zeta = 100

tol = 0.001 ## tolerance 

#########################################

x1 = rbinom(N,1,0.5)

x2 = rbinom(N,1,0.5)

x3 = rbinom(N,1,0.5)

x4 = rbinom(N,1,0.5)

x5 = rbinom(N,1,0.5)

x = cbind(x1,x2,x3,x4,x5)   #### covariate matrix, N by p

#############################################

v <- runif(N, 0, 1)


t <-  10*(exp(-log(v)*(exp(as.matrix(x)%*%theta0))^(-1))-1)## failure time for each individual 

C <- runif(N,0,tau) ## observation time for each individual 

phi = 1*( t<=C)  ######  true individual results

gamma = alpha + beta - 1

temp.groups = c()

for(i in 1:n){

temp.groups = c(temp.groups, rep(i,each = gs[i]))

}

groups = permute(temp.groups) ####

Ys = sapply(1:n, FUN = function(X){  ###### group testing results

temp  = phi[groups == X]

Delta = ifelse(sum(temp) != 0, 1, 0) ######  true group results

######  add misclassification

Y = ifelse(Delta == 1, 

rbinom(1, 1, prob = alpha), 

rbinom(1, 1, prob = 1-beta)   ) 

Y

})

###  Naive method ## set sensitivity and specificity to be 1 in the analysis

Y.i = sapply(1:N, FUN = function(X){

ifelse(phi[X]==1, 

rbinom(1, 1, prob = alpha), 

rbinom(1, 1, prob = 1-beta)) }) 


L=R=d1=d2=d3 = rep(0,N)

d1= Y.i

d3 = 1-Y.i

L[Y.i==1] = 0

L[Y.i==0] = C[Y.i==0]

R[Y.i==1] = C[Y.i==1]

R[Y.i==0] = Inf


ph.est = fast.PH.ICsurv.EM(d1, d2, d3, L, R, x, n.int=8, order=3, g0=rep(1,11), b0=rep(0,p), tol=0.001,
t.seq=seq(0,57,1), equal = TRUE)

the.est.naive =ph.est$b 

sd.the.naive = sqrt(diag(ph.est$var.b)) 

cp.the.naive = (the.est.naive-1.96*sd.the.naive < theta0)*(theta0< the.est.naive +1.96*sd.the.naive)


######## implement the proposed method

order.C = seq(min(C),max(C),length.out= K_n)
k = length(order.C)

Ind.xlab = matrix(rep(order.C,each =p.knots),p.knots,K_n) <= matrix(rep(xlab.t, K_n),p.knots,K_n)

Lambda.true = log(0.1*xlab.t+1)

g.n = list()

j = 1
for(j in 1:n){

g.n[[j]] = length(C[groups == j])
 
}

Ind.C = list()

j = 1
for(j in 1:n){

Ind.C[[j]] = matrix(rep(order.C,each = g.n[[j]] ),g.n[[j]] ,k) <= matrix(rep(C[groups == j],k), g.n[[j]] , k)
 
}

theta.ini = rep(0,p)

lambda.ini = rep(1/N,k)

theta.hat = theta.ini

lambda.hat = lambda.ini

############ judge start ##############

while(diff.zeta >= tol && loops < max.loops){

############   E-Step

W = S = E.phi = E.Z = list()

E.Zk  = rep(0,k)

num = denom =  0

j = 1
for(j in 1:n){

W[[j]] = rowSums(matrix(rep(lambda.hat, each=g.n[[j]] ), g.n[[j]] , k)*
matrix(rep(exp(x[groups == j,]%*%as.matrix(theta.hat)),k),g.n[[j]] ,k)*Ind.C[[j]] ) 

S[[j]] = exp(-W[[j]])

E.phi[[j]] = Ys[j]*alpha*(1-S[[j]])/(alpha-gamma*prod(S[[j]])) + 
(1-Ys[j])*(1-alpha)*(1-S[[j]])/(1-alpha+gamma*prod(S[[j]]))

E.Z[[j]] = matrix(rep(lambda.hat, each=g.n[[j]]),g.n[[j]], k)*
                 matrix(rep(exp(x[groups == j,]%*%as.matrix(theta.hat)),k),g.n[[j]],k)*
                 (E.phi[[j]]*(1-S[[j]])^(-1)*Ind.C[[j]] + (1-Ind.C[[j]])) 

E.Zk = E.Zk +  apply(E.Z[[j]],2,sum)

temp.x = NULL

if(length(x[groups == j,]) == p){temp.x =x[groups == j,]} else temp.x = t(x[groups == j,])

num = num + temp.x%*%as.matrix(exp(x[groups == j,]%*%as.matrix(theta.hat))) #### p by 1

denom = denom + sum(exp(x[groups == j,]%*%as.matrix(theta.hat)))   #####  1 by 1

}

###########M-step

U = I = E.Z.sum = 0

j = 1
for(j in 1:n){

U = U + t(as.matrix(x[groups == j,] - matrix(rep(num/denom,each=g.n[[j]]),g.n[[j]],p)))%*%as.matrix(apply(
as.matrix(E.Z[[j]]),1,sum))

E.Z.sum = E.Z.sum + sum(E.Z[[j]])

}

lambda.est = E.Zk/sum(exp(as.matrix(x)%*%as.matrix(theta.hat)))

#####if(any(is.na(lambda.est))) lambda.est = lambda.ini

################################################################

II = -(t(as.matrix(x))%*%(as.vector(exp(x%*%theta.hat))*x)*
denom-as.matrix(num)%*%t(as.matrix(num)))/denom^2

I = E.Z.sum*II

theta.est = theta.hat - solve(I)%*%U

####if(any(is.na(theta.est))) theta.est = theta.ini

######################################################################

diff.theta = abs(theta.est-theta.hat)
diff.lambda = abs(lambda.est-lambda.hat)


diff.zeta = max(diff.theta, diff.lambda)

theta.hat = theta.est
lambda.hat = lambda.est

loops = loops+1

} ######### judge end #########

the.est = theta.hat

lam.est = lambda.hat

loop[iter]=loops


#####  resampling starts for variance estimation

xxx <- foreach(bs = 1:n.bs, .combine = cbind, .packages = c("doParallel",
"doRNG"),.errorhandling = "remove")%dorng%{

w <- rgamma(n,1,1)  ##### group's weight

diff.zeta = 100

loops = 0

tol =  0.001

theta.hat = the.est

lambda.hat = lam.est

############ judge start ##############

while(diff.zeta >= tol && loops < max.loops){

############   E-Step

W = S = E.phi = E.Z = list()

E.Zk  = rep(0,k)

num = denom = I.num = 0

j = 1
for(j in 1:n){

W[[j]] = rowSums(matrix(rep(lambda.hat, each=g.n[[j]] ), g.n[[j]] , k)*
matrix(rep(exp(x[groups == j,]%*%as.matrix(theta.hat)),k),g.n[[j]] ,k)*Ind.C[[j]] ) 

S[[j]] = exp(-W[[j]])

E.phi[[j]] = Ys[j]*alpha*(1-S[[j]])/(alpha-gamma*prod(S[[j]])) + 
(1-Ys[j])*(1-alpha)*(1-S[[j]])/(1-alpha+gamma*prod(S[[j]]))

E.Z[[j]] = matrix(rep(lambda.hat, each=g.n[[j]]),g.n[[j]], k)*
                 matrix(rep(exp(x[groups == j,]%*%as.matrix(theta.hat)),k),g.n[[j]],k)*
                 (E.phi[[j]]*(1-S[[j]])^(-1)*Ind.C[[j]] + (1-Ind.C[[j]])) 

E.Zk = E.Zk +  apply(w[j]*E.Z[[j]],2,sum)

temp.x = NULL

if(length(x[groups == j,]) == p){temp.x =x[groups == j,]} else temp.x = t(x[groups == j,])

num = num + w[j]*temp.x%*%as.matrix(exp(x[groups == j,]%*%as.matrix(theta.hat))) #### p by 1

denom = denom + w[j]*sum(exp(x[groups == j,]%*%as.matrix(theta.hat)))   #####  1 by 1

I.num = I.num + w[j]*as.matrix(temp.x)%*%(x[groups == j,]*as.vector(exp(x[groups == j,]%*%as.matrix(theta.hat))))

}

###########M-step

U = I = E.Z.sum = 0

j = 1
for(j in 1:n){

U = U + w[j]*t(as.matrix(x[groups == j,] - matrix(rep(num/denom,each=g.n[[j]]),g.n[[j]],p)))%*%as.matrix(apply(
as.matrix(E.Z[[j]]),1,sum))

E.Z.sum = E.Z.sum + sum(w[j]*E.Z[[j]])

}

lambda.est = E.Zk/denom

#####if(any(is.na(lambda.est))) lambda.est = lambda.ini

################################################################

II = -(I.num*denom-as.matrix(num)%*%t(as.matrix(num)))/denom^2

I = E.Z.sum*II

theta.est = theta.hat - solve(I)%*%U

####if(any(is.na(theta.est))) theta.est = theta.ini

######################################################################

diff.theta = abs(theta.est-theta.hat)
diff.lambda = abs(lambda.est-lambda.hat)

diff.zeta = max(diff.theta, diff.lambda)

theta.hat = theta.est
lambda.hat = lambda.est

loops = loops+1

} ######### judge end #########

Lambda.hat =  rowSums(matrix(rep(lambda.hat,each =p.knots),p.knots,K_n)*Ind.xlab)

return(c(theta.hat,Lambda.hat))
}

### resampling ends

sd.zeta = apply(xxx,1,sd) 

sd.theta = sd.zeta[1:p]

sd.Lambda = sd.zeta[(p+1):(p+p.knots)]

cp.theta = (the.est-1.96*sd.theta < theta0)*(theta0< the.est +1.96*sd.theta)

theta.all[iter,]=as.vector(the.est)

see.theta.all[iter,]=as.vector(sd.theta)

cp.theta.all[iter,]=as.vector(cp.theta)

Lambda.est = rowSums(matrix(rep(lam.est,each =p.knots),p.knots,K_n)*Ind.xlab)

Lambda.all[iter,] = Lambda.est

see.Lambda.all[iter,] = sd.Lambda

cp.Lam.log = (Lambda.est*exp(-1.96*sd.Lambda/Lambda.est) < Lambda.true)*
                       (Lambda.true<Lambda.est*exp(1.96*sd.Lambda/Lambda.est))

cp.Lambda.all[iter,] = cp.Lam.log

theta.naive[iter,] = as.vector(the.est.naive)
see.theta.naive[iter,] = as.vector(sd.the.naive)
cp.theta.naive[iter,] = as.vector(cp.the.naive)

R.rate[iter] = 1-mean(phi)

}

### output

print(c('n=',n))
print(c('theta0=',theta0))



print(c("bias.theta=",  (apply(theta.all,2,mean)-theta0)))
print(c("sd.theta=", apply(theta.all,2,sd)))
print(c("see.theta=", apply(see.theta.all,2,mean)))
print(c("cp.theta=", apply(cp.theta.all,2,mean)))



mean(R.rate) # right censoring rate

mean(loop>=max.loops) # non-convergence rate

print(c('alpha=',alpha))
print(c('beta=',beta))

time2 = date()

print(rbind(time1,time2))


stopCluster(ccl)







