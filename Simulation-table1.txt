##In this file, we give the code of the proposed group testing method with \alpha=\beta=1, two covariates and fixed group size being 5.
##One can easily make some modifications to the code to obtain other results in the Table 1. 


library(gtools)
library(doParallel)
library(doRNG)
library(ICsurv)

time1= date()


N = 10000 ## number of individuals

gs = 5  ##### group size 

n = N/gs  ##### group number

K_n = floor(10*n^(1/3))

mm = 500  ### number of replicates

n.bs = 100 ## resampling sample size

n.cores = 25 ## number of cores used in the parallel computation

##n.cores = detectCores()

ccl <- makeCluster(n.cores)  ## make cluster

registerDoParallel(ccl) 

max.loops = 1000 ## maximum number of iteration

theta0 = c(0.5, -0.5) ## trues value of regression parameters

p <- length(theta0)  ### dimension of regression vector

tau = 2 ## the observation time C is generated from U(0,tau)

xlab.t = c(1,1.2,1.5,1.7)  ## times of interest, at which we obtain the survival function estimates

p.knots = length(xlab.t)  ## length of times of interest

theta.all = matrix(1,mm,p)
see.theta.all = matrix(1,mm,p)
cp.theta.all = matrix(1,mm,p)

Lambda.all = matrix(1,mm,p.knots)
see.Lambda.all = matrix(1,mm,p.knots)
cp.Lambda.all = matrix(1,mm,p.knots)

theta.naive = matrix(1,mm,p)
see.theta.naive = matrix(1,mm,p)
cp.theta.naive = matrix(1,mm,p)

R.rate = c()

loop=c()

###############################
seed.start = 100

iter = 1
for( iter in 1:mm){

set.seed(seed.start+iter)

loops = 0

diff.zeta = 100

tol = 0.001

#########################################

x1 = rbinom(N,1,0.5)

x2 = runif(N,0,1)

x = cbind(x1,x2)  #### N by p

#############################################

v <- runif(N, 0, 1)

##### t <-  exp(-log(v)*(exp(as.matrix(x)%*%theta0))^(-1))-1

##### t <- 5*(-log(v))*exp(-as.matrix(x)%*%theta0)

t <-  10*(exp(-log(v)*(exp(as.matrix(x)%*%theta0))^(-1))-1)##Zeng 2016

C <- runif(N,0,tau)

phi = 1*( t<=C)  ######  true individual results

alpha =  beta = 1

#####alpha =  beta = 1

gamma = alpha + beta - 1

groups = permute(rep(1:ceiling(N/gs), length.out = N))

Ys = sapply(1:ceiling(N/gs), FUN = function(X){  ###### group testing results

temp  = phi[groups == X]

Delta = ifelse(sum(temp) != 0, 1, 0) ######  true group results

######  add misclassification

Y = ifelse(Delta == 1, 

rbinom(1, 1, prob = alpha), 

rbinom(1, 1, prob = 1-beta)   ) 

Y

})


#########################################

order.C = seq(min(C),max(C),length.out= K_n)
k = length(order.C)

Ind.xlab = matrix(rep(order.C,each =p.knots),p.knots,K_n) <= matrix(rep(xlab.t, K_n),p.knots,K_n)

Lambda.true = log(0.1*xlab.t+1)

g.n = list()

j = 1
for(j in 1:ceiling(N/gs)){

g.n[[j]] = length(C[groups == j])
 
}

Ind.C = list()

j = 1
for(j in 1:ceiling(N/gs)){

Ind.C[[j]] = matrix(rep(order.C,each = g.n[[j]] ),g.n[[j]] ,k) <= matrix(rep(C[groups == j],k), g.n[[j]] , k)
 
}

theta.ini = rep(0,p)

lambda.ini = rep(1/N,k)

theta.hat = theta.ini

lambda.hat = lambda.ini

############ judge start ##############

while(diff.zeta >= tol && loops < max.loops){

############   E-Step

W = S = E.phi = E.Z = list()

E.Zk  = rep(0,k)

num = denom =  0

j = 1
for(j in 1:ceiling(N/gs)){

W[[j]] = rowSums(matrix(rep(lambda.hat, each=g.n[[j]] ), g.n[[j]] , k)*
matrix(rep(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat)),k),g.n[[j]] ,k)*Ind.C[[j]] ) 

S[[j]] = exp(-W[[j]])

E.phi[[j]] = Ys[j]*alpha*(1-S[[j]])/(alpha-gamma*prod(S[[j]])) + 
(1-Ys[j])*(1-alpha)*(1-S[[j]])/(1-alpha+gamma*prod(S[[j]]))

E.Z[[j]] = matrix(rep(lambda.hat, each=g.n[[j]]),g.n[[j]], k)*
                 matrix(rep(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat)),k),g.n[[j]],k)*
                 (E.phi[[j]]*(1-S[[j]])^(-1)*Ind.C[[j]] + (1-Ind.C[[j]])) 

E.Zk = E.Zk +  apply(E.Z[[j]],2,sum)

num = num + t(x[groups == j,])%*%as.matrix(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat))) #### p by 1

denom = denom + sum(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat)))   #####  1 by 1

}

###########M-step

U = I = E.Z.sum = 0

j = 1
for(j in 1:ceiling(N/gs)){

U = U + t(as.matrix(x[groups == j,] - matrix(rep(num/denom,each=g.n[[j]]),g.n[[j]],p)))%*%as.matrix(apply(
as.matrix(E.Z[[j]]),1,sum))

E.Z.sum = E.Z.sum + sum(E.Z[[j]])

}

lambda.est = E.Zk/sum(exp(as.matrix(x)%*%as.matrix(theta.hat)))

#####if(any(is.na(lambda.est))) lambda.est = lambda.ini

################################################################

II = -(t(as.matrix(x))%*%(as.vector(exp(x%*%theta.hat))*x)*
denom-as.matrix(num)%*%t(as.matrix(num)))/denom^2

I = E.Z.sum*II

theta.est = theta.hat - solve(I)%*%U

####if(any(is.na(theta.est))) theta.est = theta.ini

######################################################################

diff.theta = abs(theta.est-theta.hat)
diff.lambda = abs(lambda.est-lambda.hat)


diff.zeta = max(diff.theta, diff.lambda)

theta.hat = theta.est
lambda.hat = lambda.est

loops = loops+1

} ######### judge end #########

the.est = theta.hat

lam.est = lambda.hat

loop[iter]=loops


#####  resampling starts for variance estimation

xxx <- foreach(bs = 1:n.bs, .combine = cbind, .packages = c("doParallel",
"doRNG"),.errorhandling = "remove")%dorng%{

w <- rgamma(ceiling(N/gs),1,1)  ##### group's weight

diff.zeta = 100

loops = 0

tol =  0.001

theta.hat = the.est

lambda.hat = lam.est

############ judge start ##############

while(diff.zeta >= tol && loops < max.loops){

############   E-Step

W = S = E.phi = E.Z = list()

E.Zk  = rep(0,k)

num = denom = I.num = 0

j = 1
for(j in 1:ceiling(N/gs)){

W[[j]] = rowSums(matrix(rep(lambda.hat, each=g.n[[j]] ), g.n[[j]] , k)*
matrix(rep(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat)),k),g.n[[j]] ,k)*Ind.C[[j]] ) 

S[[j]] = exp(-W[[j]])

E.phi[[j]] = Ys[j]*alpha*(1-S[[j]])/(alpha-gamma*prod(S[[j]])) + 
(1-Ys[j])*(1-alpha)*(1-S[[j]])/(1-alpha+gamma*prod(S[[j]]))

E.Z[[j]] = matrix(rep(lambda.hat, each=g.n[[j]]),g.n[[j]], k)*
                 matrix(rep(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat)),k),g.n[[j]],k)*
                 (E.phi[[j]]*(1-S[[j]])^(-1)*Ind.C[[j]] + (1-Ind.C[[j]])) 

E.Zk = E.Zk +  apply(w[j]*E.Z[[j]],2,sum)

num = num + w[j]*t(x[groups == j,])%*%as.matrix(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat))) #### p by 1

denom = denom + w[j]*sum(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat)))   #####  1 by 1

I.num = I.num + w[j]*t(x[groups == j,])%*%(x[groups == j,]*as.vector(exp(as.matrix(x[groups == j,])%*%as.matrix(theta.hat))))

}

###########M-step

U = I = E.Z.sum = 0

j = 1
for(j in 1:ceiling(N/gs)){

U = U + w[j]*t(as.matrix(x[groups == j,] - matrix(rep(num/denom,each=g.n[[j]]),g.n[[j]],p)))%*%as.matrix(apply(
as.matrix(E.Z[[j]]),1,sum))

E.Z.sum = E.Z.sum + sum(w[j]*E.Z[[j]])

}

lambda.est = E.Zk/denom

#####if(any(is.na(lambda.est))) lambda.est = lambda.ini

################################################################

II = -(I.num*denom-as.matrix(num)%*%t(as.matrix(num)))/denom^2

I = E.Z.sum*II

theta.est = theta.hat - solve(I)%*%U

####if(any(is.na(theta.est))) theta.est = theta.ini

######################################################################

diff.theta = abs(theta.est-theta.hat)
diff.lambda = abs(lambda.est-lambda.hat)

diff.zeta = max(diff.theta, diff.lambda)

theta.hat = theta.est
lambda.hat = lambda.est

loops = loops+1

} ######### judge end #########

Lambda.hat =  rowSums(matrix(rep(lambda.hat,each =p.knots),p.knots,K_n)*Ind.xlab)

return(c(theta.hat,Lambda.hat))
}

### resampling ends

sd.zeta = apply(xxx,1,sd) 

sd.theta = sd.zeta[1:p]

sd.Lambda = sd.zeta[(p+1):(p+p.knots)]

cp.theta = (the.est-1.96*sd.theta < theta0)*(theta0< the.est +1.96*sd.theta)

theta.all[iter,]=as.vector(the.est)

see.theta.all[iter,]=as.vector(sd.theta)

cp.theta.all[iter,]=as.vector(cp.theta)

Lambda.est = rowSums(matrix(rep(lam.est,each =p.knots),p.knots,K_n)*Ind.xlab)

Lambda.all[iter,] = Lambda.est

see.Lambda.all[iter,] = sd.Lambda

cp.Lam.log = (Lambda.est*exp(-1.96*sd.Lambda/Lambda.est) < Lambda.true)*
                       (Lambda.true<Lambda.est*exp(1.96*sd.Lambda/Lambda.est))

cp.Lambda.all[iter,] = cp.Lam.log

R.rate[iter] = 1-mean(phi)

}

### output

print(c('n=',n))
print(c('theta0=',theta0))



print(c("bias.theta=",  (apply(theta.all,2,mean)-theta0)))
print(c("sd.theta=", apply(theta.all,2,sd)))
print(c("see.theta=", apply(see.theta.all,2,mean)))
print(c("cp.theta=", apply(cp.theta.all,2,mean)))

#print(c("Lambda.true=", Lambda.true))
#print(c("bias.Lambda=", apply(Lambda.all,2,mean)-Lambda.true))
#print(c("sd.Lambda=", apply(Lambda.all,2,sd)))
#print(c("see.Lambda=", apply(see.Lambda.all,2,mean)))
#print(c("cp.Lambda.log=", apply(cp.Lambda.all,2,mean)))


mean(R.rate) # right censoring rate

mean(loop>=max.loops) # non-convergence rate

print(c('alpha=',alpha))
print(c('beta=',beta))

time2 = date()

print(rbind(time1,time2))


stopCluster(ccl)







